{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8ad6407a3e453315f9b29644ba7dd4d8",
     "grade": false,
     "grade_id": "cell-84617f606b66d110",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Artificial Intelligence UE\n",
    "## Assignment 3 - Game Playing\n",
    "\n",
    "<div class=\"alert alert-danger\"\">\n",
    "    <strong>Deadline: </strong> 25.11.2024, 12:00 (noon)\n",
    "</div>\n",
    "\n",
    "In this assignment you are looking at game playing - more precisely, at the Minimax algorithm, Alpha-Beta pruning and Q-Learning. \n",
    "\n",
    "The algorithms have been explained in the lecture (VO) and we gave you some additional information in the exercise (UE). Please refer to the lecture slides (VO) for the pseudo algorithms and the exercise slides (UE) for additional hints.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<p><strong>Automatic Grading:</strong></p>\n",
    "<ul>\n",
    "<li>Replace the placeholders <code># YOUR CODE HERE</code>, <code>raise NotImplementedError()</code> with your code.</li>\n",
    "<li>Do not rename any of the already existing variables (this might lead to hidden tests failing / not working).</li>\n",
    "<li>Do not delete or add cells.</li>\n",
    "<li>Hint: Once you've completed your implementation, if you're unsure whether any unintended changes were made to the original notebook, create a fresh copy of the provided notebook. Then, transfer your implementations to the new notebook before submitting.</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Submission:</strong> Upload the notebook containing your implementation, and change its name s.t. it contains \"a3\" and your student ID: </p>\n",
    "\n",
    "    a3_<k/vk + 8 digits>.ipynb ; e.g., a3_01234567.ipynb\n",
    "\n",
    "\n",
    "\n",
    "<p><strong>Practical hints:</strong></p>\n",
    "<ul>\n",
    "<li>if you want a number smaller than all others, you may use <code>float('-Inf')</code></li>\n",
    "<li>if you want a number larger than all others, you may use <code>float('Inf')</code></li>\n",
    "</ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f6aa7b610ced6df3c25d748b625c832",
     "grade": false,
     "grade_id": "cell-9f190755dfdee1fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# import stuff\n",
    "from pig_lite.game.base import Game, Node\n",
    "from pig_lite.environment.base import Environment, Outcome\n",
    "from pig_lite.instance_generation.problem_factory import ProblemFactory\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b437a5fbb3d537fe50aca48ad9b6cb95",
     "grade": false,
     "grade_id": "cell-2f0104814be2be96",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Small Intro into the World of TicTacToe\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<p><strong>TicTacToe Visualisation</strong></p>\n",
    "If you want to see a nicer visualization of your game tree and not just a textual description of game nodes, make sure to install the following packages within your <code>conda</code> environment:\n",
    "<ul>\n",
    "    <li>First, activate your environment: <code>conda activate ai2024</code></li>\n",
    "    <li><code>conda install graphviz</code></li>\n",
    "    <li><code>conda install networkx</code></li>\n",
    "    <li><code>conda install pydot</code></li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can generate a new game board of TicTacToe as follows; note that the problem_size here describes the depth of the board in a game tree\n",
    "rng = np.random.RandomState(seed=123)\n",
    "game = ProblemFactory().generate_problem('tictactoe', problem_size=3, rng=rng)\n",
    "\n",
    "# or, you can load an existing one from a .json file like so:\n",
    "game = ProblemFactory().create_problem_from_json(json_path='boards/game.json')\n",
    "\n",
    "# if we use Minimax / Alphabeta pruning to derive a move sequence, we can visualise it as follows:\n",
    "move_sequence = [(-1, (0, 2)), (1, (1, 1)), (-1, (1, 2)), (1, (0, 0)), (-1, (2, 0))] # arbitrary move sequence for demonstration purposes\n",
    "game.visualize(move_sequence, show_possible=False, tree_name='Arbitrary Tree 1')\n",
    "# if we set show_possible to True, the function shows all possible moves from a state in the path\n",
    "game.visualize(move_sequence, show_possible=True, tree_name='Arbitrary Tree 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b5ea3ed6f8202be1daeb526dc6561d5",
     "grade": false,
     "grade_id": "cell-8ca2076d79b78bdb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Minimax (4 points)\n",
    "\n",
    "Now, let us implement the Minimax algorithm!\n",
    "\n",
    "**NOTE**: If multiple paths lead to the same outcome for these algorithms, choose the first expanded / leftmost path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b4382686aacd28991f7d0ee2a8d0ad2",
     "grade": false,
     "grade_id": "cell-c5c2a2df427bd111",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Minimax():\n",
    "    def play(self, game: Game):\n",
    "        \"\"\" Starts game playing, and returns found terminal node according to minimax. \"\"\"\n",
    "        start = game.get_start_node()\n",
    "        # 'game.get_max_player()' asks the game how it identifies the MAX player internally\n",
    "        value, terminal_node = self.minimax(game, start, game.get_max_player())\n",
    "        return terminal_node\n",
    "\n",
    "    def minimax(self, game, node, max_player):\n",
    "        \"\"\" Performs minimax algorithm (recursively). \"\"\"\n",
    "        # here we check if the current node 'node' is a terminal node\n",
    "        terminal, winner = game.outcome(node)\n",
    "\n",
    "        # if it is a terminal node, determine who won, and return\n",
    "        # a) the utility value (-1, 0, 1)\n",
    "        # and b) the terminal node itself, to be able to determine the path of moves/plies that led to this terminal node\n",
    "        if terminal:\n",
    "            if winner is None:\n",
    "                return 0, node\n",
    "            elif winner == max_player:\n",
    "                return 1, node\n",
    "            else:\n",
    "                return -1, node\n",
    "\n",
    "        # TODO: implement the minimax algorithm recursively here\n",
    "        if node.player == max_player:\n",
    "            # you have to remember the best value *and* the best node for the MAX player (TODO: initialise appropriately)\n",
    "            best_value, best_node = None, None\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "            return best_value, best_node\n",
    "        else:\n",
    "            # you have to remember the best value *and* the best node for the MIN player (TODO: initialise appropriately)\n",
    "            best_value, best_node = None, None\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "            return best_value, best_node\n",
    "\n",
    "game = ProblemFactory().create_problem_from_json(json_path='boards/game.json')\n",
    "outcome = Minimax().play(game)\n",
    "minimax_nodes = game.get_number_of_expanded_nodes()\n",
    "\n",
    "if outcome is not None:\n",
    "    terminated, winner = game.outcome(outcome)\n",
    "    print('Game terminated: {}, winner is: {} (1: Max, -1: Min); nr of expanded nodes: {}'.format(terminated, winner, minimax_nodes))\n",
    "    outcome.pretty_print()\n",
    "    game.visualize(game.get_move_sequence(outcome), False, 'Minimax Tree')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d3e4eedfbbb67fbf94e4e920a6766ed0",
     "grade": true,
     "grade_id": "cell-69d1bdefa9930127",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test cell, don't edit or delete\n",
    "# check found path here \n",
    "assert(outcome is not None), 'Minimax returned None, something is wrong with the implementation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ca776249176418a77b481acce666881",
     "grade": true,
     "grade_id": "cell-c3fb982c8f3e0663",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test cell, don't edit or delete\n",
    "assert(outcome is not None), 'Minimax pruning returned None, something is wrong with the implementation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd8349714ce034a42b23a660a0748d7e",
     "grade": true,
     "grade_id": "cell-d955df46dc4a948b",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test cell, don't edit or delete\n",
    "assert(outcome is not None), 'Minimax pruning returned None, something is wrong with the implementation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e344a60a7dbe36b2f3a9d07b954605ef",
     "grade": true,
     "grade_id": "cell-7d888625c8c74fc2",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test cell, don't edit or delete\n",
    "assert(outcome is not None), 'Minimax pruning returned None, something is wrong with the implementation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a193644850a713791c13fa095a12ca91",
     "grade": true,
     "grade_id": "cell-be5f3456e9709954",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test cell, don't edit or delete\n",
    "# check found path here \n",
    "assert(outcome is not None), 'Minimax pruning returned None, something is wrong with the implementation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e63040212be771ba2ad1295d136d251c",
     "grade": true,
     "grade_id": "cell-49f6d6596e9c5173",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test cell, don't edit or delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06eed9507befc68b376aa6582c4e95d3",
     "grade": true,
     "grade_id": "cell-bffa5f3e5a1380a5",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test cell, don't edit or delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56cdfe3a8f6fae4d5546ea2142c05c72",
     "grade": false,
     "grade_id": "cell-592b6c2a2d4b5c05",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Alpha-Beta Pruning (4 points)\n",
    "\n",
    "Here, let us implement Alpha-Beta pruning. \n",
    "\n",
    "**NOTE**: If multiple paths lead to the same outcome for these algorithms, choose the first expanded / leftmost path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1968a996abb1b95f3e682fbbdbb1aaf9",
     "grade": false,
     "grade_id": "cell-d2df9b0e3d90cf00",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AlphaBeta(object):\n",
    "    def play(self, game: Game):\n",
    "        \"\"\" Starts game playing, and returns found terminal node according to alpha-beta pruning. \"\"\"\n",
    "        start = game.get_start_node()\n",
    "        alpha = float('-Inf')\n",
    "        beta = float('Inf')\n",
    "        value, terminal_node = self.alphabeta(game, start, alpha, beta, game.get_max_player())\n",
    "        return terminal_node\n",
    "\n",
    "    def alphabeta(self, game, node, alpha, beta, max_player):\n",
    "        \"\"\" Performs alpha-beta pruning algorithm (recursively). \"\"\"\n",
    "        # here we check if the current node 'node' is a terminal node\n",
    "        terminal, winner = game.outcome(node)\n",
    "        # if it is a terminal node, determine who won, and return\n",
    "        if terminal:\n",
    "            if winner is None:\n",
    "                return 0, node\n",
    "            elif winner == max_player:\n",
    "                return 1, node\n",
    "            else:\n",
    "                return -1, node\n",
    "\n",
    "        # TODO: implement the alpha-beta pruning algorithm recursively here\n",
    "        # the structure should be almost the same as for minimax\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "game = ProblemFactory().create_problem_from_json(json_path='boards/game.json')\n",
    "outcome = AlphaBeta().play(game)\n",
    "alphabeta_nodes = game.get_number_of_expanded_nodes()\n",
    "\n",
    "if outcome is not None:\n",
    "    terminated, winner = game.outcome(outcome)\n",
    "    print('Game terminated: {}, winner is: {} (1: Max, -1: Min); nr of expanded nodes: {}'.format(terminated, winner, alphabeta_nodes))\n",
    "    outcome.pretty_print()\n",
    "    game.visualize(game.get_move_sequence(outcome), False, 'Alpha-Beta Tree')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "458736acf00f1d309bbdb6dd2d60ae36",
     "grade": false,
     "grade_id": "cell-c8aa7d319fc1f6cb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Alpha-Beta Pruning Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "628e832968ecaf9661d7c1558f4b4c2a",
     "grade": true,
     "grade_id": "cell-2db5203948b220c7",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test cell, don't edit or delete\n",
    "# check found path here \n",
    "assert(outcome is not None), 'Alpha-beta pruning returned None, something is wrong with the implementation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e95813d3b44ba6d50f9119d50eab768",
     "grade": true,
     "grade_id": "cell-5e7587f893fa567c",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test cell, don't edit or delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9381e1f4c2ac8003d902e5f9b5588c47",
     "grade": true,
     "grade_id": "cell-127304dc5089e06c",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test cell, don't edit or delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "537b7d53cb488cf9101125539cc0a7ab",
     "grade": true,
     "grade_id": "cell-20ca8862d1e2a714",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test cell, don't edit or delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6fae809dea780e5ea7ffde127d02346a",
     "grade": true,
     "grade_id": "cell-a5135148f16e856c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test cell, don't edit or delete\n",
    "# check expanded nodes here (whether we actually save something compared to minimax)\n",
    "assert(alphabeta_nodes < minimax_nodes), 'Alpha-beta pruning took more node expansions than minimax - something must be off here...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72fb64ee8ca993489335cf25abdd5314",
     "grade": true,
     "grade_id": "cell-8200230398bb339a",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test cell, don't edit or delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "487ead4c2a3dd76b7ac9172582bd106c",
     "grade": true,
     "grade_id": "cell-94bfb871ef2c6230",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test cell, don't edit or delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7c02e622c196e587436f0154ece2cb7e",
     "grade": false,
     "grade_id": "cell-568544c7786aea22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Small Intro into the Gridworld\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "For Q-Learing, we require another new problem type - we here look at a stochastic gridworld.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can generate a new gridworld as follows\n",
    "rng = np.random.RandomState(seed=123)\n",
    "env = ProblemFactory().generate_problem('gridworld', problem_size=3, rng=rng)\n",
    "\n",
    "# or, you can load an existing one from a .json file like so:\n",
    "env_json = ProblemFactory().create_problem_from_json(json_path='boards/environment.json')\n",
    "\n",
    "# if we use Q-Learning to learn the Q-function, we can visualise its results as follows:\n",
    "rand_policy = np.array([[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0], [1, 0, 0, 0], [1, 0, 0, 0]])\n",
    "outcome = Outcome(1, rand_policy, np.random.randn(env.get_n_states()),       # arbitrary outcome for demonstration purposes\n",
    "                  np.random.randn(env.get_n_states(), env.get_n_actions())) \n",
    "env.visualize(outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "67a6393cdaeb7ffbb4f24cb140be6d12",
     "grade": false,
     "grade_id": "cell-233204deb4eb05b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q-Learning (7 points)\n",
    "   \n",
    "<strong>Remember: To interact with the (Q-Learning) enviroment, you need</strong>\n",
    "<ul>\n",
    "<li><code>state = env.reset()</code> to reset the environment at the start of an episode</li>\n",
    "<li><code>state, reward, done = env.step(action)</code> to tell the environment that your agent decided to take `action`. The environment then tells you in which state you actually ended up in (<code>state</code>), what the immediate reward was (<code>reward</code>), and whether or not the episode ended (<code>done</code>).</li>\n",
    "  \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "821ca68de69249798a088c934cb78858",
     "grade": false,
     "grade_id": "cell-1bbd4598c8d0500f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def eps_greedy(rng, qs, epsilon):\n",
    "    \"\"\" Makes an epsilon greedy decision between exploration (trying out a new option) and exploitation (choosing best option so far). \"\"\"\n",
    "    if rng.uniform(0, 1) < epsilon:\n",
    "        # with probability p == epsilon, an action is chosen uniformly at random\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    else:\n",
    "        # with probability p == 1 - epsilon, the action having the currently largest q-value estimate is chosen\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    # this is to avoid errors if there is no implementation yet - you can remove it if you want\n",
    "    return -1\n",
    "\n",
    "class QLearning():\n",
    "    def train(self, env: Environment, n_episodes=10000, alpha=0.2):\n",
    "        \"\"\" Performs Q-Learning for given environment. \"\"\"\n",
    "        # leave untouched for final submission (for sake of reproducability)\n",
    "        self.rng = np.random.RandomState(1234)\n",
    "        self.epsilon = 0.3\n",
    "        self.gamma = env.get_gamma()\n",
    "\n",
    "        # initialize the Q-'table'\n",
    "        Q = np.zeros((env.get_n_states(), env.get_n_actions()))\n",
    "\n",
    "        for episode in range(1, n_episodes + 1):\n",
    "            # implement q-learning update here: generate an episode, interact with environment with env.reset() and env.step(action)\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        # compute a deterministic policy from the Q value function\n",
    "        policy = np.zeros((env.get_n_states(), env.get_n_actions()), dtype=np.int64)\n",
    "        policy[np.arange(len(policy)), np.argmax(Q, axis=1)] = 1\n",
    "        # finally, compute the state value function V here\n",
    "        # it can be computed easily from Q by taking the action that leads to the max future reward\n",
    "        V = None\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        return Outcome(n_episodes, policy, V=V, Q=Q)\n",
    "\n",
    "\n",
    "environment = ProblemFactory().create_problem_from_json(json_path='boards/environment.json')\n",
    "qlearn = QLearning()\n",
    "outcome = qlearn.train(environment)\n",
    "\n",
    "if outcome is not None:\n",
    "    environment.visualize(outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9b840bfe6c132101d4d814e0dc258945",
     "grade": false,
     "grade_id": "cell-ac953a8ab55a2747",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q-Learning Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0bfad6b83e1452e8393153812e342a7a",
     "grade": true,
     "grade_id": "cell-724a9b7bd5e49b48",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test cell, don't edit or delete\n",
    "# here we check whether default variables were modified\n",
    "assert(qlearn.epsilon == 0.3), 'Epsilon was changed for Q-Learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f8197770dfbf56eb616046b0cccdc350",
     "grade": true,
     "grade_id": "cell-321985c0232e9f93",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test cell, don't edit or delete\n",
    "# here we check a few (hidden) test instances for their resulting policy (encoded in a hash-value)\n",
    "assert(environment.get_policy_hash(outcome) == 'a138e26bebdd61e38fc045f03a37ee77bc3343dc36cb3f1cf415707a9b5e08ad' or\n",
    "       environment.get_policy_hash(outcome) == '6c8ec07e309222af5c0839f8a6fb58597135356f451dc61c624a1ebea86735fe'), 'algorithm did not find same optimal policy as ours, so there is probably something off'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c1de01e4ccafd40a47a1445a073d813b",
     "grade": true,
     "grade_id": "cell-096b0e848bc26030",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test cell, don't edit or delete\n",
    "# here we check whether eps_greedy was implemented (correctly)\n",
    "assert(eps_greedy(qlearn.rng, outcome.Q[env.reset()], qlearn.epsilon) != -1), 'eps_greedy does not appear to be implemented (correctly) yet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a08b4b3474cbb45e02956252c3030b8",
     "grade": true,
     "grade_id": "cell-3c0c3a8168ade782",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test cell, don't edit or delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c78ab892387acb684c7379ac2b81435",
     "grade": true,
     "grade_id": "cell-3781060b1950225f",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test cell, don't edit or delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad759cdcae011122fca040ac31a61dc8",
     "grade": true,
     "grade_id": "cell-7e0012c0d1af9a1c",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test cell, don't edit or delete\n",
    "# here we check whether V was computed\n",
    "assert(outcome.V is not None), 'V was not computed (correctly)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36a236de2c5b10dbe5ba8b4619e587ab",
     "grade": true,
     "grade_id": "cell-aecdeb8567515f69",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test cell, don't edit or delete"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
